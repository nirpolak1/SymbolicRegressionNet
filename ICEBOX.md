# ICEBOX (V2: Advanced Pipeline)

This document contains a structured backlog of ideas and tasks to improve the SymbolicRegressionNet program. The suggestions were generated by systematically "clocking in" as each specialized team member, proposing improvements from their domain, and supplementing with independent deep research on state-of-the-art symbolic regression (SR) from 2024-2025. 

All completed Phase 1 epics (like AVX2, L-BFGS, Grammar Constraints, Transformers) have been removed.

Each suggestion is ranked by **Complexity** (Low, Medium, High) and **Impact** (Low, Medium, High).

---

## Team Member Suggestions

### GP Specialist (`clock-in`)
*   **Algorithm: Monte Carlo Tree Search (MCTS) for Symbolic Regression**
    *   *Idea:* Replace or supplement the standard genetic algorithm with MCTS using extreme bandit allocation. This balances exploration and exploitation better for discrete expression topologies, jumping to globally optimal states faster than random crossover.
    *   *Complexity:* High
    *   *Impact:* High
*`clock-out`*

### Machine Learning Engineer (`clock-in`)
*   **Algorithm: LLM In-Context Seed Generation**
    *   *Idea:* Send the dataset summary (variable names, correlation matrix, target variance) to a local LLM or API to propose highly probable mathematical functional forms and non-linear feature combinations as starting seeds.
    *   *Complexity:* Medium
    *   *Impact:* High
*`clock-out`*

### Numerical Optimization Engineer (`clock-in`)
*   **Algorithm: Mixed-Integer Non-Linear Programming (MINLP) Constant Snapping**
    *   *Idea:* Traditional L-BFGS optimizes floating-point constants well, but many physical formulas rely on exact rational integers (e.g., $c^2$, $1/2$). Add a discrete optimizer step to snap and freeze floating constants to neighboring exact integers/fractions, evaluating fitness.
    *   *Complexity:* High
    *   *Impact:* Medium
*`clock-out`*

### Performance Engineer (`clock-in`)
*   **Performance: JIT Compilation of AST to Native Machine Code (Emit IL)**
    *   *Idea:* Even with FastStackEvaluator and AVX2, interpreting the AST incurs pointer overhead. Use `System.Reflection.Emit` to compile the best Pareto front expressions directly into native C# bytecode delegates for absolute maximum evaluation speed.
    *   *Complexity:* High
    *   *Impact:* High
*`clock-out`*

### QA Engineer (`clock-in`)
*   **Testing: Automated Metamorphic Testing Infrastructure**
    *   *Idea:* Provide the engine a known equation $f(x)$, run it, then provide $f(x) + x - x$ or $f(x) \times \frac{x}{x}$. Validate that the CAS and engine can effectively reduce and solve the metamorphic relations flawlessly without regression failures.
    *   *Complexity:* Medium
    *   *Impact:* Medium
*`clock-out`*

---

## Independent Deep Research

The following ideas were sourced from modern state-of-the-art symbolic regression frameworks and 2024-2025 literature (e.g., AI Feynman 2.0, ICML/NeurIPS 2024 SR papers) and do not duplicate the team members' suggestions.

*   **E-Graphs (Equality Graphs) for Redundancy Elimination**
    *   *Idea:* Implement an E-Graph data structure to represent the population. E-graphs identify and consolidate mathematically equivalent expressions natively during the search (e.g., treating `x+x` and `2*x` as the same node pool), drastically reducing evaluation costs for duplicate phenotypic trees.
    *   *Complexity:* High
    *   *Impact:* High

*   **Minimum Description Length (MDL) Information-Theoretic Fitness**
    *   *Idea:* Instead of strict MSE + Pareto depth constraints, use Information Theory (MDL principle) as the single fitness objective function to mathematically balance complexity vs. accuracy based on the absolute bits required to encode the tree.
    *   *Complexity:* Medium
    *   *Impact:* High
